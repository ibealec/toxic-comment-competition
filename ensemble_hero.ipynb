{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Hero\n",
    "\n",
    "This notebook is for testing different ensemble / blending strategies. It's important to note that the submissions and their weights are chosen in response to their effectiveness in the Public Leaderboard. This is the main caveat with blending. This intuition will not necessarily transfer to other datasets, nor will it likely be as effective on the Private Leaderboard, which could have a different distribution of data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Averaging ensemble\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "classes = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "\n",
    "input_submissions = [\n",
    "    # Weight 3\n",
    "    './submissions/bidlstm_01.csv',\n",
    "    './submissions/nbsvm_02.csv',\n",
    "    './submissions/convgru_kern.csv',\n",
    "    './submissions/capsnet_01.csv',\n",
    "    \n",
    "    # Weight 2\n",
    "    './submissions/ft_bidlstm_01.csv',\n",
    "    './submissions/submission-tuned-LR-01.csv'\n",
    "    './submissions/blend_it_all.csv',\n",
    "    './submissions/charreg_02.csv'\n",
    "]\n",
    "denominator = 0\n",
    "ensemble = pd.read_csv(input_submissions[0]).copy()\n",
    "print('Creating ensemble...')\n",
    "for i, sub in enumerate(input_submissions):\n",
    "    if i < 4:\n",
    "        ensemble[classes] += pd.read_csv(sub)[classes] * 4\n",
    "        denominator += 4\n",
    "    if i == 3 or i == 4:\n",
    "        ensemble[classes] += pd.read_csv(sub)[classes] * 3\n",
    "        denominator += 3\n",
    "    \n",
    "ensemble[classes] / denominator\n",
    "\n",
    "ensemble_path = './submissions/ensemble_07.csv'\n",
    "ensemble.to_csv(ensemble_path, index=False)\n",
    "\n",
    "print('Ensemble written to {}'.format(ensemble_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Toxic Avenger\n",
    "\n",
    "This code is used for blending with Extra Trees Classifier. Taken directly from https://www.kaggle.com/the1owl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import *\n",
    "from textblob import TextBlob\n",
    "\n",
    "zpolarity = {0:'zero',1:'one',2:'two',3:'three',4:'four',5:'five',6:'six',7:'seven',8:'eight',9:'nine',10:'ten'}\n",
    "zsign = {-1:'negative',  0.: 'neutral', 1:'positive'}\n",
    "\n",
    "train = pd.read_csv('./input/train.csv')\n",
    "test = pd.read_csv('./input/test.csv')\n",
    "sub1 = pd.read_csv('./submissions/ensemble_07.csv')\n",
    "\n",
    "coly = [c for c in train.columns if c not in ['id','comment_text']]\n",
    "y = train[coly]\n",
    "tid = test['id'].values\n",
    "\n",
    "train['polarity'] = train['comment_text'].map(lambda x: int(TextBlob(x).sentiment.polarity * 10))\n",
    "test['polarity'] = test['comment_text'].map(lambda x: int(TextBlob(x).sentiment.polarity * 10))\n",
    "\n",
    "train['comment_text'] = train.apply(lambda r: str(r['comment_text']) + ' polarity' +  zsign[np.sign(r['polarity'])] + zpolarity[np.abs(r['polarity'])], axis=1)\n",
    "test['comment_text'] = test.apply(lambda r: str(r['comment_text']) + ' polarity' +  zsign[np.sign(r['polarity'])] + zpolarity[np.abs(r['polarity'])], axis=1)\n",
    "\n",
    "df = pd.concat([train['comment_text'], test['comment_text']], axis=0)\n",
    "df = df.fillna(\"unknown\")\n",
    "nrow = train.shape[0]\n",
    "\n",
    "tfidf = feature_extraction.text.TfidfVectorizer(stop_words='english', max_features=800000)\n",
    "data = tfidf.fit_transform(df)\n",
    "\n",
    "model = ensemble.ExtraTreesClassifier(n_jobs=-1, random_state=3)\n",
    "model.fit(data[:nrow], y)\n",
    "print(1- model.score(data[:nrow], y))\n",
    "sub2 = model.predict_proba(data[nrow:])\n",
    "sub2 = pd.DataFrame([[c[1] for c in sub2[row]] for row in range(len(sub2))]).T\n",
    "sub2.columns = coly\n",
    "sub2['id'] = tid\n",
    "for c in coly:\n",
    "    sub2[c] = sub2[c].clip(0+1e12, 1-1e12)\n",
    "\n",
    "#blend 1\n",
    "sub2.columns = [x+'_' if x not in ['id'] else x for x in sub2.columns]\n",
    "blend = pd.merge(sub1, sub2, how='left', on='id')\n",
    "for c in coly:\n",
    "    blend[c] = blend[c] * 0.8 + blend[c+'_'] * 0.2\n",
    "    blend[c] = blend[c].clip(0+1e12, 1-1e12)\n",
    "blend = blend[sub1.columns]\n",
    "\n",
    "#blend 2\n",
    "sub2 = blend[:]\n",
    "sub2.columns = [x+'_' if x not in ['id'] else x for x in sub2.columns]\n",
    "blend = pd.merge(sub1, sub2, how='left', on='id')\n",
    "for c in coly:\n",
    "    blend[c] = np.sqrt(blend[c] * blend[c+'_'])\n",
    "    blend[c] = blend[c].clip(0+1e12, 1-1e12)\n",
    "blend = blend[sub1.columns]\n",
    "blend.to_csv('submissions/avenger_04.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
